{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.4.0 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)\n",
      "ERROR: No matching distribution found for torch==1.4.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==2.9.0 in c:\\users\\arane\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from transformers==2.9.0) (2020.6.8)\n",
      "Requirement already satisfied: numpy in c:\\users\\arane\\anaconda3\\lib\\site-packages (from transformers==2.9.0) (1.18.5)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from transformers==2.9.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from transformers==2.9.0) (4.47.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\arane\\anaconda3\\lib\\site-packages (from transformers==2.9.0) (3.0.12)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\arane\\anaconda3\\lib\\site-packages (from transformers==2.9.0) (0.1.91)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\arane\\anaconda3\\lib\\site-packages (from transformers==2.9.0) (0.0.43)\n",
      "Requirement already satisfied: requests in c:\\users\\arane\\anaconda3\\lib\\site-packages (from transformers==2.9.0) (2.24.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\arane\\anaconda3\\lib\\site-packages (from sacremoses->transformers==2.9.0) (0.16.0)\n",
      "Requirement already satisfied: six in c:\\users\\arane\\anaconda3\\lib\\site-packages (from sacremoses->transformers==2.9.0) (1.15.0)\n",
      "Requirement already satisfied: click in c:\\users\\arane\\anaconda3\\lib\\site-packages (from sacremoses->transformers==2.9.0) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from requests->transformers==2.9.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from requests->transformers==2.9.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from requests->transformers==2.9.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from requests->transformers==2.9.0) (1.25.9)\n",
      "Requirement already satisfied: pytorch_lightning==0.7.5 in c:\\users\\arane\\anaconda3\\lib\\site-packages (0.7.5)\n",
      "Requirement already satisfied: numpy>=1.16.4 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from pytorch_lightning==0.7.5) (1.18.5)\n",
      "Requirement already satisfied: future>=0.17.1 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from pytorch_lightning==0.7.5) (0.18.2)\n",
      "Requirement already satisfied: tensorboard>=1.14 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from pytorch_lightning==0.7.5) (2.3.0)\n",
      "Requirement already satisfied: torch>=1.1 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from pytorch_lightning==0.7.5) (1.6.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from pytorch_lightning==0.7.5) (4.47.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (49.2.0.post20200714)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.10.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\arane\\anaconda3\\lib\\site-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (3.13.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.15.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.20.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.31.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (1.25.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.7.5) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\arane\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (4.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\arane\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.4.0\n",
    "!pip install transformers==2.9.0\n",
    "!pip install pytorch_lightning==0.7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_paraphraser')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"device \",device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickle_file_name.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model,  'pickle_file_name.pkl',compress=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = pickle.load(open('model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"questions- alex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Questions '][3]=\"whats is your name? | where do you live ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(sentence):\n",
    "    text =  \"paraphrase: \" + sentence + \" </s>\"\n",
    "\n",
    "    encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    # set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "    beam_outputs = model.generate(\n",
    "        input_ids=input_ids, attention_mask=attention_masks,\n",
    "        do_sample=True,\n",
    "        max_length=256,\n",
    "        top_k=120,\n",
    "        top_p=0.98,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences=10\n",
    "    )\n",
    "\n",
    "#     print (\"\\nOriginal Question ::\")\n",
    "#     print (sentence)\n",
    "#     print (\"\\n\")\n",
    "#     print (\"Paraphrased Questions :: \")\n",
    "    final_outputs =[]\n",
    "    for beam_output in beam_outputs:\n",
    "        sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "        if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
    "            final_outputs.append(sent)\n",
    "    \n",
    "    return final_outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def findmatches(pattern, phrase):\n",
    "\n",
    "    for p in patterns:\n",
    "        match= re.findall(p, phrase)\n",
    "    return match[0]\n",
    "\n",
    "patterns= ['[^!.?]+']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "for i in df['Questions ']:\n",
    "    final_outputs=[]\n",
    "    if \"|\" in i:\n",
    "        x=i.split('|')\n",
    "        for j in x:\n",
    "            final_outputs.append(generator(j))\n",
    "    \n",
    "        final_outputs = [item for sublist in final_outputs for item in sublist]\n",
    "        output={}\n",
    "        for c, final_output in enumerate(final_outputs):\n",
    "            output[c]=final_output  \n",
    "        filename=findmatches(patterns, i)\n",
    "        with open(\"%s.csv\"%filename, 'w') as csv_file:  \n",
    "            writer = csv.writer(csv_file)\n",
    "            for key, value in output.items():\n",
    "                writer.writerow([key, value])\n",
    "    else:           \n",
    "        final_outputs=generator(i) \n",
    "       \n",
    "        output={}\n",
    "        for c, final_output in enumerate(final_outputs):\n",
    "            output[c]=final_output  \n",
    "        \n",
    "        filename=findmatches(patterns, i)\n",
    "        with open(\"%s.csv\"%filename, 'w') as csv_file:  \n",
    "            writer = csv.writer(csv_file)\n",
    "            for key, value in output.items():\n",
    "                writer.writerow([key, value])\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('are you guys data driven firm .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Are you guys Data driven firm?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Are you guys data driven firm? If yes, what do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Are you guys data driven firm?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Are you guys data driven startup?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Are you guys data driven company?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Are you guys data driven business?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Are you guys a data driven?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                     Are you guys Data driven firm?\n",
       "0  1  Are you guys data driven firm? If yes, what do...\n",
       "1  2                     Are you guys data driven firm?\n",
       "2  3                  Are you guys data driven startup?\n",
       "3  4                  Are you guys data driven company?\n",
       "4  5                 Are you guys data driven business?\n",
       "5  6                        Are you guys a data driven?"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #1 has length 0; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-f7250706ffe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'are you guys data driven firm .csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmydict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: dictionary update sequence element #1 has length 0; 2 is required"
     ]
    }
   ],
   "source": [
    "with open('are you guys data driven firm .csv') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    mydict = dict(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
